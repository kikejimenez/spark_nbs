# Spark Notebooks

> Notebooks with code examples from  the [*Learning Spark* (_Second Edition_)](https://learning.oreilly.com/library/view/learning-spark-2nd) book.

## Structure

The notebook run in pyspark or scala-spark. At the begiining of the notebook each case is specified.

## Scala Spark

To run Scala in a notebook, the are two tools available:

- [Spylon-Kernel](https://github.com/Valassis-Digital-Media/spylon-kernel)
- [Almond](https://github.com/almond-sh/almond)

## Docker Containers

To properly run Spark in a notebook you may use:

- [pyspark & Spylon-Kernel](https://github.com/jupyter/docker-stacks/tree/master/all-spark-notebook)

- [Almond](https://hub.docker.com/r/almondsh/almond)

## Datasets

The datasets are taken from  _databricks-datasets_ directory in the [*Learning Spark* repo](https://learning.oreilly.com/library/view/learning-spark-2nd), this directory must be placed in the root folder of this repo.

## References

- [Learning Spark Book](https://learning.oreilly.com/library/view/learning-spark-2nd)
- [Github Learnin Spark](https://github.com/databricks/LearningSparkV2)
