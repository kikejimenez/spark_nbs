{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Learning Spark Second Edition](https://github.com/databricks/LearningSparkV2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Chapter 9](https://learning.oreilly.com/library/view/learning-spark-2nd/9781492050032/ch09.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _pyspark_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python\n",
    "# Configure source data path\n",
    "\n",
    "# In Python\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "# Create a SparkSession\n",
    "\n",
    "\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages io.delta:delta-core_2.12:0.7.0 pyspark-shell'\n",
    "\n",
    "PARENT_DIR = os.popen('dirname $PWD').read().strip()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.7.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sourcePath = os.path.join(\n",
    "    PARENT_DIR,\n",
    "    'databricks-datasets/learning-spark-v2/loans/'+\\\n",
    "              'loan-risks.snappy.parquet'\n",
    ")\n",
    "\n",
    "# Configure Delta Lake path\n",
    "deltaPath = os.path.join(\"/tmp\",\"loans_delta\")\n",
    "\n",
    "# Create the Delta Lake table with the same loans data\n",
    "(spark.read.format(\"parquet\")\n",
    "           .load(sourcePath)\n",
    "           .write\n",
    "           .mode('overwrite')\n",
    "           .format(\"delta\")\n",
    "           .save(deltaPath))\n",
    "\n",
    "# Create a view on the data called loans_delta\n",
    "(spark.read.format(\"delta\")\n",
    " .load(deltaPath)\n",
    " .createOrReplaceTempView(\"loans_delta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   14705|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filePath = \"\"\"/databricks-datasets/learning-spark-v2/sf-airbnb/\n",
    "sf-airbnb-clean.parquet/\"\"\"\n",
    "airbnbDF = spark.read.parquet(filePath)\n",
    "airbnbDF.select(\"neighbourhood_cleansed\", \"room_type\", \"bedrooms\", \"bathrooms\", \n",
    "                \"number_of_reviews\", \"price\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+---------+----------+\n",
      "|loan_id|funded_amnt|paid_amnt|addr_state|\n",
      "+-------+-----------+---------+----------+\n",
      "|      0|       1000|   182.22|        CA|\n",
      "|      1|       1000|   361.19|        WA|\n",
      "|      2|       1000|   176.26|        TX|\n",
      "|      3|       1000|   1000.0|        OK|\n",
      "|      4|       1000|   249.98|        PA|\n",
      "+-------+-----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM loans_delta LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "assert os.path.isdir(deltaPath)\n",
    "rmtree(deltaPath,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
